{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s-I6b_fhpPzU"
      },
      "outputs": [],
      "source": [
        "import requests as rq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = rq.get('https://en.wikipedia.org/wiki/William_Feller')"
      ],
      "metadata": {
        "id": "op_QAns5rGCz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp.content"
      ],
      "metadata": {
        "id": "Y04be1nZrR-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "ok25FgMprztL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advisor = BeautifulSoup(resp.content).find(lambda tag: tag.name=='tr' and 'student' in tag.text.lower())"
      ],
      "metadata": {
        "id": "srYL5Gvlr6Ay"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advisors = advisor.find_all(lambda tag: tag.name=='a' and ('student' not in tag.text.lower()))"
      ],
      "metadata": {
        "id": "7DFdRhs1sB6M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in advisors:\n",
        "  print((item.text, item['href']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DR2-sP2trSS",
        "outputId": "021eddb4-b6a7-4a33-938a-0f66bcfa54e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Patrick Billingsley', '/wiki/Patrick_Billingsley')\n",
            "('George Forsythe', '/wiki/George_Forsythe')\n",
            "('Henry McKean', '/wiki/Henry_McKean')\n",
            "('Lawrence Shepp', '/wiki/Lawrence_Shepp')\n",
            "('Hale Trotter', '/wiki/Hale_Trotter')\n",
            "('Benjamin Weiss', '/wiki/Benjamin_Weiss')\n",
            "('David A. Freedman', '/wiki/David_A._Freedman')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_info(page_url):\n",
        "  # concat the base url\n",
        "  base_url = 'https://en.wikipedia.org'\n",
        "  url = base_url + page_url\n",
        "  # send a request to receive the content\n",
        "  resp = rq.get(url)\n",
        "  content = resp.content\n",
        "  # parse the contents\n",
        "  soup = BeautifulSoup(content)\n",
        "  result = {}\n",
        "  for entry in ['student', 'advisor']:\n",
        "    result[entry] = []\n",
        "    entry_block = soup.find('table', {'class', 'infobox'}).find(lambda tag: tag.name=='tr' and entry in tag.text.lower())\n",
        "    entries = entry_block.find_all(lambda tag: tag.name=='a' and (entry not in tag.text.lower()))\n",
        "    for item in entries:\n",
        "      if len(item.text) > 6:\n",
        "        result[entry].append((item['href'], item.text))\n",
        "  return result"
      ],
      "metadata": {
        "id": "s6rs8lTCv7JS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "init = ('/wiki/William_Feller', 'William Feller')\n",
        "\n",
        "queue = [init]\n",
        "visited_nodes = set()\n",
        "\n",
        "graph = nx.DiGraph()\n",
        "\n",
        "while len(queue) > 0:\n",
        "  \n",
        "  page = queue.pop(0)\n",
        "\n",
        "  visited_nodes.add(page[0])\n",
        "\n",
        "  try:\n",
        "    data = get_page_info(page[0])\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "  for advisor in data['advisor']:\n",
        "    if advisor[0] not in visited_nodes:\n",
        "      queue.append(advisor)\n",
        "      visited_nodes.add(advisor[0])\n",
        "      graph.add_edge(advisor[1], page[1])\n",
        "\n",
        "  for student in data['student']:\n",
        "    if student[0] not in visited_nodes:\n",
        "      queue.append(student)\n",
        "      visited_nodes.add(student[0])\n",
        "      graph.add_edge(page[1], student[1])"
      ],
      "metadata": {
        "id": "YCLfk3y9YwWl"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.write_edgelist(graph, 'graph.csv', delimiter=',', data=False)"
      ],
      "metadata": {
        "id": "o_wJpnjvmK7w"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10 graph.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAwiStKwm3cS",
        "outputId": "0beb5f57-c686-402b-9b6e-10b5e9c27038"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Richard Courant,William Feller\n",
            "Richard Courant,Leifur √Åsgeirsson\n",
            "Richard Courant,Herbert Busemann\n",
            "Richard Courant,Kurt Friedrichs\n",
            "Richard Courant,Harold Grad\n",
            "Richard Courant,Fritz John\n",
            "Richard Courant,Joseph Keller\n",
            "Richard Courant,Edgar Krahn\n",
            "Richard Courant,Martin Kruskal\n",
            "Richard Courant,Anneli Lax\n"
          ]
        }
      ]
    }
  ]
}